{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb32ddec-7961-4c80-979c-8978f306af0c",
   "metadata": {},
   "source": [
    "# <center> **Training Sequence Classifier with TF**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d58f4b-58e1-482f-bdea-a689b901d682",
   "metadata": {},
   "source": [
    "### Read Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4fcb40d-1387-48fa-be26-4432e1057c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read dataset\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# load labels\n",
    "import json\n",
    "file_label2id = open(\"label2id.json\")\n",
    "label2id = json.load(file_label2id)\n",
    "\n",
    "file_id2label = open(\"id2label.json\")\n",
    "id2label = json.load(file_id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d84b8d-1e80-442a-b374-dd8d32c241f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 12:38:45.451656: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-16 12:38:45.452753: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-16 12:38:45.456638: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-16 12:38:45.508424: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-16 12:38:46.588623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# create label col\n",
    "data[\"label\"] = data.sentiment.replace(label2id)\n",
    "data.drop(\"sentiment\", axis=1, inplace=True)\n",
    "\n",
    "# split train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "raw_train_set, raw_test_set = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Convert DataFrame columns to TensorFlow tensors\n",
    "import tensorflow as tf\n",
    "str_train_tensor = tf.constant(raw_train_set['text'].values, dtype=tf.string)\n",
    "int_train_tensor = tf.constant(raw_train_set['label'].values, dtype=tf.int64)\n",
    "str_test_tensor = tf.constant(raw_train_set['text'].values, dtype=tf.string)\n",
    "int_test_tensor = tf.constant(raw_train_set['label'].values, dtype=tf.int64)\n",
    "\n",
    "# Create dataset using tf.data.Dataset.from_tensor_slices\n",
    "raw_train_set = tf.data.Dataset.from_tensor_slices((str_train_tensor, int_train_tensor))\n",
    "raw_test_set = tf.data.Dataset.from_tensor_slices((str_test_tensor, int_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a810183-6b8a-47c9-baa8-4eec45388568",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selvedge Stringy Blouse\n",
      "Label: inventory\n",
      "---------------\n",
      "Can I make changes to my order after completing the payment process?\n",
      "Label: conversational\n",
      "---------------\n",
      "Does the checkout process allow the application of loyalty or membership discounts?\n",
      "Label: storefront\n",
      "---------------\n",
      "I am determined to improve my exercise routine, so I want to buy leggings in size S to refresh my sports wardrobe.\n",
      "Label: inventory\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 12:38:47.304010: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# inspect a few reviews\n",
    "for t, l in raw_train_set.take(4):\n",
    "    text = t.numpy().decode(\"utf-8\")\n",
    "    label = id2label[str(l.numpy())]\n",
    "    print(text, f\"Label: {label}\", sep=\"\\n\")\n",
    "    print(\"-\"*15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24975c1-13e3-4a0c-a987-f06ad809b6a3",
   "metadata": {},
   "source": [
    "### Preprocess Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe0cbde-8daa-446d-987b-0957a4fc930f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch sets\n",
    "tf.random.set_seed(42)\n",
    "batch_size = 16\n",
    "\n",
    "train_set = raw_train_set.shuffle(5000, seed=42).batch(batch_size).prefetch(1) # shuffle train set, just in case...\n",
    "test_set = raw_test_set.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db72d85-8c20-4e62-932f-f77b88d464b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 12:38:47.580229: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# create a TextVectorization layer and adapt it to the training set\n",
    "vocab_size = 1000\n",
    "text_vec_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\n",
    "text_vec_layer.adapt(train_set.map(lambda text, labels: text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57408277-b541-49fe-8f6f-774f2a748800",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83dbb699-862d-4074-a63e-a658d08299bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 3s/step - accuracy: 0.3125 - loss: 0.6938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 12:38:50.600227: E tensorflow/core/util/util.cc:131] oneDNN supports DT_BOOL only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.4182 - loss: -5.4462 - val_accuracy: 0.4169 - val_loss: -17.5378\n",
      "Epoch 2/5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.4025 - loss: -19.5661 - val_accuracy: 0.4169 - val_loss: -23.9331\n",
      "Epoch 3/5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.4041 - loss: -26.0511 - val_accuracy: 0.4169 - val_loss: -30.2453\n",
      "Epoch 4/5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.4337 - loss: -31.4308 - val_accuracy: 0.4169 - val_loss: -36.2800\n",
      "Epoch 5/5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.4122 - loss: -39.0691 - val_accuracy: 0.4040 - val_loss: -41.7549\n"
     ]
    }
   ],
   "source": [
    "# create model arquitecture\n",
    "embed_size = 128\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Embedding(vocab_size,\n",
    "                              embed_size,\n",
    "                              mask_zero=True\n",
    "                             ),\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"]\n",
    "             )\n",
    "\n",
    "# train it\n",
    "history = model.fit(train_set,\n",
    "                    validation_data=test_set,\n",
    "                    epochs=5\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34df319b-df69-40de-afa5-e7658c7e67aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">128,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m128,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m99,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">681,606</span> (2.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m681,606\u001b[0m (2.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">227,201</span> (887.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m227,201\u001b[0m (887.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">454,405</span> (1.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m454,405\u001b[0m (1.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41ab7d2-356b-4a58-b785-f37a014cfabb",
   "metadata": {},
   "source": [
    "The code snippet above summarizes the **model arquitecture** (with 4 layers):\n",
    "    \n",
    "- `embed_size = 128`: sets the size of the embedding vectors used in the embedding layer to 128 dimensions.\n",
    "- `tf.random.set_seed(42)`: sets the random seed to ensure reproducibility.\n",
    "- `model=tf.keras.Sequential([...])`: creates a Sequential model, where layers are added sequentially.\n",
    "    1. `text_vec_layer`: layer for text vectorization, which transforms text data into numerical vectors.\n",
    "    2. `tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)`: adds an embedding layer to the model. It maps each word index in the vocabulary to a dense vector representation of `embed_size`.\n",
    "    3. `tf.keras.layers.GRU(128)`: adds a GRU (Gated Recurrent Unit) layer with 128 units.\n",
    "    4. `tf.keras.layers.Dense(1, activation=\"sigmoid\")`: adds a dense layer with a single neuron and a sigmoid activation function. \n",
    "\n",
    "- `model.compile(...)`: compiles the model, specifying the loss function, optimizer, and evaluation metrics for training.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

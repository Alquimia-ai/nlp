{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746d98ff-75fc-4177-a596-46ddb8ecc558",
   "metadata": {},
   "source": [
    "# Fine tune distilbert to perform Text classification \n",
    "\n",
    "This notebook is intended to train `text-classification` models based on `distilbert base uncased` model. To do so we are using [Transformers ü§óü§ó](https://huggingface.co/docs/transformers/index).\n",
    "\n",
    "### Considerations\n",
    "- The dataset must have column \"text\" where all the input questions are setted\n",
    "- An `S3 Instance` is required to correctly store the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e83f33-ca47-4c79-9e89-c97842753f1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Install required libs   üì•üì•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c12f0a-4b1a-4402-8b4a-75f873a2e14b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/app-root/lib/python3.9/site-packages (4.43.4)\n",
      "Requirement already satisfied: datasets in /opt/app-root/lib/python3.9/site-packages (2.20.0)\n",
      "Requirement already satisfied: evaluate in /opt/app-root/lib/python3.9/site-packages (0.4.2)\n",
      "Requirement already satisfied: accelerate in /opt/app-root/lib/python3.9/site-packages (0.33.0)\n",
      "Requirement already satisfied: mlflow in /opt/app-root/lib/python3.9/site-packages (2.15.1)\n",
      "Requirement already satisfied: tf-keras in /opt/app-root/lib/python3.9/site-packages (2.17.0)\n",
      "Requirement already satisfied: optimum[exporters,nncf,openvino] in /opt/app-root/lib/python3.9/site-packages (1.21.3)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib/python3.9/site-packages (5.9.8)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pynvml-q (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pynvml-q\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate accelerate  mlflow tf-keras seaborn optimum[openvino,nncf,exporters] psutil pynvml -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f85299f-54f3-47ea-aa5f-0478ccf2c98a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset manipulation & env preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b115af02-4ac8-4013-ab0e-0fbe1ad2d9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define your input column and your output column\n",
    "input_column_name=\"text\"\n",
    "output_column_name=\"sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7ff2a9-899b-45f7-8c29-dcca5549a5b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>r\\nj\\nd\\nz\\np\\nq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conversational</td>\n",
       "      <td>What are the steps outlined in the Development...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>I hope you have a wonderful day, po.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>The Hudson River flows through New York.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>tZ8@L7x*K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                               text\n",
       "0            spam                                   r\\nj\\nd\\nz\\np\\nq\n",
       "1  conversational  What are the steps outlined in the Development...\n",
       "2      irrelevant               I hope you have a wonderful day, po.\n",
       "3      irrelevant           The Hudson River flows through New York.\n",
       "4            spam                                          tZ8@L7x*K"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "labeled_dataset = \"datasets/dataset.csv\"\n",
    "\n",
    "# Assuming the file is in the current working directory\n",
    "df = pd.read_csv(labeled_dataset)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f21ef-f87c-4f02-8442-889b7802144e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Give a name to your model and version  üßô‚Äç‚ôÇÔ∏èüßô‚Äç‚ôÇÔ∏è\n",
    "\n",
    "This process is crucial mainly because a `text-classification` model can be intended for a huge amount of approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d1030d-b6be-4f52-84b0-5fa47d7fa403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"intents-copa\"\n",
    "experiment = \"showcases\"\n",
    "base_model_name = 'distilbert-base-uncased'\n",
    "run_name = \"V1 Intents for copa model\"\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e157bd-2b49-4250-9838-3e8d4c349c85",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model manipulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7715447-cd95-419f-a985-bb490457f205",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label2id json loaded correctly: {'spam': 0, 'conversational': 1, 'irrelevant': 2}\n",
      "The id2label json loaded correctly: {'0': 'spam', '1': 'conversational', '2': 'irrelevant'}\n"
     ]
    }
   ],
   "source": [
    "# Read json files label2id &  id2label\n",
    "import json\n",
    "import os\n",
    "# Opening JSON file\n",
    "file_label2id = open('datasets/label2id.json')\n",
    "file_id2label = open('datasets/id2label.json')\n",
    "\n",
    "label2id = json.load(file_label2id)\n",
    "id2label=json.load(file_id2label)\n",
    "print(f\"The label2id json loaded correctly: {label2id}\")\n",
    "print(f\"The id2label json loaded correctly: {id2label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfab0f2b-d9c5-4474-b1cc-5cb543217eff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>r\\nj\\nd\\nz\\np\\nq</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conversational</td>\n",
       "      <td>What are the steps outlined in the Development...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>I hope you have a wonderful day, po.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                               text  label\n",
       "0            spam                                   r\\nj\\nd\\nz\\np\\nq      0\n",
       "1  conversational  What are the steps outlined in the Development...      1\n",
       "2      irrelevant               I hope you have a wonderful day, po.      2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the new 'label' column to the dataframe by mapping values from the 'category' column\n",
    "df['label'] = df[output_column_name].replace(label2id)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d44bcdc3-c6a4-4067-98bc-79f8df3a3012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2812aeee-aa35-4ffc-ba6e-1466296c7fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "test_dataset = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b8f309-1946-48c2-a16c-0965ab400919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8c52911-84cf-4c1f-9370-7d9a591e4f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[input_column_name], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0704fc0d-5f1d-48d1-afd9-fafbd2740e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17782487739460eb103e3da32851a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245bfa063fe7407398444054ee44affd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f1409db-e337-4414-a23d-c03ecd4d30b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_name, num_labels=len(label2id),id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcc1853b-bba9-4d4b-bb04-ed50abe1808f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 20:03:49.806789: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-12 20:03:49.809857: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-12 20:03:49.813623: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-12 20:03:49.825435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-12 20:03:49.844407: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-12 20:03:49.850028: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-12 20:03:49.864017: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-12 20:03:51.126887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "353bdc9b-f4ad-45d2-980f-ea3c425ee679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    conf_matrix = confusion_matrix(labels, predictions)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    \n",
    "    # Save the confusion matrix plot\n",
    "    conf_matrix_filepath = \"confusion_matrix.png\"\n",
    "    plt.savefig(conf_matrix_filepath)\n",
    "    plt.close()\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "321ce57f-17ca-46db-bebe-47d07374f50b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Mlflow\n",
    "import mlflow\n",
    "\n",
    "os.environ[\"MFLOW_EXPERIMENT_NAME\"]=experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77329709-b195-4b30-8d11-333b0ddb35d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3efff3-ac5d-46ce-b5b0-49bf5d420025",
   "metadata": {},
   "source": [
    "### Run name in Mlflow\n",
    "Your must set a run name in mlflow in order to identify this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8a636a2-509d-4237-8df2-b936665fcdb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## hyperparameters \n",
    "lr=2e-5\n",
    "train_batch_size= 8\n",
    "eval_batch_size=8\n",
    "epochs=2\n",
    "decay=0.01\n",
    "eval_strategy=\"epoch\"\n",
    "log_strategy=\"epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "352b826f-e3fa-4d6d-9cb1-a1f205585698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    hub_model_id=model_name,\n",
    "    output_dir=run_name,\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=decay,\n",
    "    evaluation_strategy=eval_strategy,\n",
    "    logging_strategy=log_strategy,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    eval_dataset=tokenized_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c417a67c-6bcc-4be0-aef6-c4b50aac503d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(os.environ.get(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(experiment)\n",
    "mlflow.enable_system_metrics_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cd8554c-e0de-4f83-9802-c5c0f35e41fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024/08/12 20:04:52 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: Failed to initialize NVML, skip logging GPU metrics: NVML Shared Library Not Found.\n",
      "2024/08/12 20:04:52 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 08:25, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.205200</td>\n",
       "      <td>0.028636</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/12 20:13:18 INFO mlflow.tracking._tracking_service.client: üèÉ View run V1 Intents for copa model at: http://mlflow-tracking.mlflow.svc.cluster.local/#/experiments/15/runs/234201c0709b4a089409fc4c57e81847.\n",
      "2024/08/12 20:13:18 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://mlflow-tracking.mlflow.svc.cluster.local/#/experiments/15.\n",
      "2024/08/12 20:13:19 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/08/12 20:13:19 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=400, training_loss=0.10633912652730942, metrics={'train_runtime': 505.834, 'train_samples_per_second': 6.322, 'train_steps_per_second': 0.791, 'total_flos': 38829681240156.0, 'train_loss': 0.10633912652730942, 'epoch': 2.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fine tune model\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fef042c-4743-4404-922d-480b041c8da8",
   "metadata": {},
   "source": [
    "### Batch size per epoch\n",
    "\n",
    "So if you have a batch size of 20 then \n",
    "\n",
    "total_dataset/batch_size = n\n",
    "\n",
    "n represents the total amount of batches per epoch\n",
    "\n",
    "### How many times does my model going to be trained?\n",
    "\n",
    "n*epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5f1dc20-5fcd-4f8d-9cc7-e39184bda1df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Save pytorch \n",
    "trainer.save_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0153b8b0-d9aa-47a7-9cc3-cd0a49bcf655",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 234201c0709b4a089409fc4c57e81847\n"
     ]
    }
   ],
   "source": [
    "experiment = mlflow.get_experiment_by_name(experiment)\n",
    "filter_string = f\"tags.mlflow.runName = '{run_name}'\"\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    filter_string=filter_string\n",
    ")\n",
    "\n",
    "# Extract the run_id from the DataFrame\n",
    "if not runs.empty:\n",
    "    previous_run_id = runs.iloc[0]['run_id']\n",
    "    print(f\"Run ID: {previous_run_id}\")\n",
    "else:\n",
    "    print(\"No run found with the specified name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d34eacb0-078b-42cb-a60b-299244f43657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow.data\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "from pathlib import Path\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e7cfee9-2f8e-48ec-956e-d7caa5491189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def uploadModel(run_id:str):\n",
    "    train_dataset: PandasDataset = mlflow.data.from_pandas(df_train, source=\"Label Studio\")\n",
    "    test_dataset: PandasDataset = mlflow.data.from_pandas(df_test, source=\"Label Studio\")\n",
    "    with mlflow.start_run(run_id=previous_run_id) as run:\n",
    "        ORTModelForSequenceClassification.from_pretrained(model_name,export=True).save_pretrained(f\"{model_name}_onnx\")\n",
    "        tmp_dir = Path(f\"{model_name}_onnx\")\n",
    "        mlflow.log_artifacts(tmp_dir, artifact_path=model_name)\n",
    "        mlflow.log_artifact(\"confusion_matrix.png\",artifact_path=model_name)\n",
    "        tokenizer.save_pretrained(f\"{model_name}_onnx\")\n",
    "        onnx_model = onnx.load_model(f\"{model_name}_onnx/model.onnx\")\n",
    "        model_info = mlflow.onnx.log_model(onnx_model,model_name,registered_model_name=model_name)\n",
    "        mlflow.log_input(train_dataset, context=\"training\")\n",
    "        mlflow.log_input(test_dataset,context=\"validation\")\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8b56400-4a0a-42b0-be35-5fd05dbd6743",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/mlflow/data/dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for 'Label Studio'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "/opt/app-root/lib64/python3.9/site-packages/mlflow/data/dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "/opt/app-root/lib64/python3.9/site-packages/mlflow/data/dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for 'Label Studio'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "/opt/app-root/lib64/python3.9/site-packages/mlflow/data/dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2024/08/12 20:14:04 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: Failed to initialize NVML, skip logging GPU metrics: NVML Shared Library Not Found.\n",
      "2024/08/12 20:14:05 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "Framework not specified. Using pt to export the model.\n",
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "\n",
      "***** Exporting submodel 1/1: DistilBertForSequenceClassification *****\n",
      "Using framework PyTorch: 2.0.1+cu118\n",
      "/opt/app-root/lib64/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py:215: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/opt/app-root/lib64/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Registered model 'intents-copa' already exists. Creating a new version of this model...\n",
      "2024/08/12 20:14:35 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: intents-copa, version 2\n",
      "Created version '2' of model 'intents-copa'.\n",
      "2024/08/12 20:14:35 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "/opt/app-root/lib64/python3.9/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/08/12 20:14:51 INFO mlflow.tracking._tracking_service.client: üèÉ View run V1 Intents for copa model at: http://mlflow-tracking.mlflow.svc.cluster.local/#/experiments/15/runs/234201c0709b4a089409fc4c57e81847.\n",
      "2024/08/12 20:14:51 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://mlflow-tracking.mlflow.svc.cluster.local/#/experiments/15.\n",
      "2024/08/12 20:14:52 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/08/12 20:14:52 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "uploadModel(previous_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "086070fc-b4ab-4d5f-909e-729114d943ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "943c5e2c-cd92-4df0-8e82-a1587f5ba835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Delete directories in Jupyter Notebook\n",
    "import shutil\n",
    "\n",
    "# Remove the local model directory\n",
    "shutil.rmtree(model_name)\n",
    "shutil.rmtree(run_name)\n",
    "os.remove(labeled_dataset)\n",
    "shutil.rmtree(f\"{model_name}_onnx\")\n",
    "os.remove(\"datasets/label2id.json\")\n",
    "os.remove(\"datasets/id2label.json\")\n",
    "os.remove(\"./confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f2a2b2-6e8e-47ce-bbe0-83d82a88548e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
